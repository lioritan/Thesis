\contentsline {figure}{\numberline {1}{\ignorespaces A decision tree for the basic features\relax }}{2}
\contentsline {figure}{\numberline {2}{\ignorespaces A constructed feature used within a decision tree\relax }}{3}
\contentsline {figure}{\numberline {3}{\ignorespaces Recursive construction of a learning problem on countries of origin. $(1)$ Creating the objects for the new problem. $(2)$ Creating features using the knowledge base. $(3)$ Applying an induction algorithm. $(4)$ The resulting feature.\relax }}{3}
\contentsline {figure}{\numberline {4}{\ignorespaces A two-level constructed feature used within a decision tree\relax }}{4}
\contentsline {figure}{\numberline {5}{\ignorespaces Accuracy of baseline approach compared to one-level activation of \emph {FEAGURE} (SVM). Each point represents a dataset. The dotted lines represent a 5 and 10 percent difference in accuracy\relax }}{11}
\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy of baseline approach compared to two-level activation of \emph {FEAGURE} (SVM). Each point represents a dataset. The dotted lines represent a 5 and 10 percent difference in accuracy\relax }}{11}
\contentsline {figure}{\numberline {7}{\ignorespaces Accuracy of baseline approach compared to single-level activation of \emph {FEAGURE} (SVM). Displayed are the 25 hardest datasets (meaning they have the lowest MAA)\relax }}{12}
\contentsline {figure}{\numberline {8}{\ignorespaces Average number of features tried vs average number of features generated per depth.\relax }}{13}
\contentsline {figure}{\numberline {9}{\ignorespaces Mean size ratio of newly created recursive problem compared to the original learning problem size (new problem training set size divided by original problem training set size).\relax }}{14}
\contentsline {figure}{\numberline {10}{\ignorespaces Mean information gain of generated features compared to the best information gain for original learning problem.\relax }}{15}
\contentsline {figure}{\numberline {11}{\ignorespaces The left box represents the original learning problem. The middle box shows the entities extracted from the original problem. The right box represents the new learning problem containing entities that serve as keys for a specific relation.\relax }}{15}
\contentsline {figure}{\numberline {12}{\ignorespaces Recursive induction problem creation process: Features are created using the relational knowledge base.\relax }}{16}
\contentsline {figure}{\numberline {13}{\ignorespaces Feature constructed by \emph {FEAGURE} for entities (organisations) in the ``owns" relation.\relax }}{16}
\contentsline {figure}{\numberline {14}{\ignorespaces Entities are extracted and labelled. These entities are the new example set. The left box shows the original learning problem. The middle box represents entities extracted from the problem. The right box shows the new learning problem containing a subset of entities in a single domain.\relax }}{17}
\contentsline {figure}{\numberline {15}{\ignorespaces Applicable relations are used as feature function for the new example set.\relax }}{17}
\contentsline {figure}{\numberline {16}{\ignorespaces Feature constructed by FEAGURE for entities (people) in the ``lives in" relation.\relax }}{18}
\contentsline {figure}{\numberline {17}{\ignorespaces Entities are extracted from the text, and entities in the ``Located in" relation are used as labelled objects.\relax }}{18}
\contentsline {figure}{\numberline {18}{\ignorespaces Construction of a recursive learning problem based on the ``Located in" relation. Applicable relations are used to create a feature set for the newly constructed example set.\relax }}{19}
\contentsline {figure}{\numberline {19}{\ignorespaces Construction of a second level recursive learning problem based on the ``Happened in" relation. Feature values are treated as objects and labelled according to the labels of the problem on locations.\relax }}{19}
\contentsline {figure}{\numberline {20}{\ignorespaces Construction of a recursive learning problem based on the ``Happened in" relation. Once the example set has been created, applicable relations are used to create a feature set for the newly constructed induction problem.\relax }}{19}
\contentsline {figure}{\numberline {21}{\ignorespaces Recursive feature constructed by \emph {FEAGURE} for entities in the ``happened in" relation. This feature operates on events, and can be used in a classifier on locations.\relax }}{20}
\contentsline {figure}{\numberline {22}{\ignorespaces Final generated feature constructed by \emph {FEAGURE} for entities in the ``located in" relation. The feature in the left branch is the recursive feature constructed by applying \emph {FEAGURE} to the new learning problem.\relax }}{20}
